{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"execution":{"iopub.status.busy":"2023-10-25T09:43:51.042284Z","iopub.execute_input":"2023-10-25T09:43:51.042932Z","iopub.status.idle":"2023-10-25T09:45:46.176776Z","shell.execute_reply.started":"2023-10-25T09:43:51.042902Z","shell.execute_reply":"2023-10-25T09:45:46.175710Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/facebookresearch/detectron2.git\n  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-lpgcbvt4\n  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-lpgcbvt4\n  Resolved https://github.com/facebookresearch/detectron2.git to commit 898507047cf441a1e4be7a729270961c401c4354\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (9.5.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (3.6.3)\nCollecting pycocotools>=2.0.2 (from detectron2==0.6)\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.3.0)\nCollecting yacs>=0.1.8 (from detectron2==0.6)\n  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (0.9.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.2.1)\nRequirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (4.64.1)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.12.3)\nCollecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\nCollecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.6)\n  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting black (from detectron2==0.6)\n  Downloading black-23.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.23.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.4.1)\nCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.0.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (4.39.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.4.4)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (2.8.2)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (8.1.3)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (1.0.0)\nCollecting packaging (from detectron2==0.6)\n  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pathspec>=0.9.0 (from black->detectron2==0.6)\n  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\nRequirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (3.5.0)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (2.0.1)\nRequirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (4.5.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.4.3)\nRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.28.2)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (59.8.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (0.7.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.3.6)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (0.40.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.7)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.16.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\nBuilding wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n  Building wheel for detectron2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=1259019 sha256=0971b432ea2d7caf3b419cf52985e050eba09a6835cc5963cab6e1107f497940\n  Stored in directory: /tmp/pip-ephem-wheel-cache-8j17esul/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=8cab02668686297462e6faea435989d090f1584901189a626cebf52cb2793db8\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144574 sha256=5d24711c6f2474181694514ca42f484e743a119c0976390c0c7df5c4079cd327\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\nSuccessfully built detectron2 fvcore antlr4-python3-runtime\nInstalling collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, packaging, omegaconf, iopath, hydra-core, black, pycocotools, fvcore, detectron2\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.6.0 requires protobuf<4.22,>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.6.0 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\ndask-cuda 23.6.0 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\ndask-cudf 23.6.0 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\ndistributed 2023.3.2.1 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.10.1 which is incompatible.\nraft-dask 23.6.1 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\nydata-profiling 4.1.2 requires scipy<1.10,>=1.4.1, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 black-23.10.1 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 omegaconf-2.3.0 packaging-23.2 pathspec-0.11.2 portalocker-2.8.2 pycocotools-2.0.7 yacs-0.1.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch, detectron2\n!nvcc --version\nTORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\nCUDA_VERSION = torch.__version__.split(\"+\")[-1]\nprint(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\nprint(\"detectron2:\", detectron2.__version__)","metadata":{"id":"2OrF5nJyGEC1","outputId":"9246c5c7-c69a-43b5-fb25-e254b61fbf0e","execution":{"iopub.status.busy":"2023-10-25T09:45:46.178874Z","iopub.execute_input":"2023-10-25T09:45:46.179205Z","iopub.status.idle":"2023-10-25T09:45:48.968444Z","shell.execute_reply.started":"2023-10-25T09:45:46.179175Z","shell.execute_reply":"2023-10-25T09:45:48.967293Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\nCuda compilation tools, release 11.8, V11.8.89\nBuild cuda_11.8.r11.8/compiler.31833905_0\ntorch:  2.0 ; cuda:  2.0.0\ndetectron2: 0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"from detectron2.config import get_cfg\nfrom detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_train_loader\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.model_zoo import model_zoo\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.structures import BoxMode\nfrom io import BytesIO\nimport os\nimport cv2\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport PIL.Image\nimport requests\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader","metadata":{"id":"RsSWYnl7H5tn","execution":{"iopub.status.busy":"2023-10-25T09:45:48.969884Z","iopub.execute_input":"2023-10-25T09:45:48.970778Z","iopub.status.idle":"2023-10-25T09:45:49.443952Z","shell.execute_reply.started":"2023-10-25T09:45:48.970735Z","shell.execute_reply":"2023-10-25T09:45:49.443083Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/content/drive')","metadata":{"id":"moLZZcqgjc_H","outputId":"78d26021-44d0-456e-cbc3-79a91042a570","execution":{"iopub.status.busy":"2023-10-25T09:45:49.446248Z","iopub.execute_input":"2023-10-25T09:45:49.446543Z","iopub.status.idle":"2023-10-25T09:45:49.450696Z","shell.execute_reply.started":"2023-10-25T09:45:49.446518Z","shell.execute_reply":"2023-10-25T09:45:49.449766Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#MappingLabelStudio créer une instance à partir du fichier .json générer par LabelStudio\ndataset_path = \"/kaggle/input/galica\"\n#dataset_path = \"/content/drive/MyDrive/Colab Notebooks/BNF/envoi1/envoi1/dataset\"\n\njson_file = dataset_path + \"/galica/gallicaimages_set1.json\"\nimage_dir =  dataset_path + \"/image\"\n\ncategory_dict = {\n  'tampon': 0,\n  'écriture manuscrite': 1,\n  'écriture typographique': 2,\n  'photographie': 3,\n  'estampe': 4,\n  'décoration' : 5\n}","metadata":{"id":"hwwlYricPwLg","execution":{"iopub.status.busy":"2023-10-25T09:45:49.451980Z","iopub.execute_input":"2023-10-25T09:45:49.452230Z","iopub.status.idle":"2023-10-25T09:45:49.465412Z","shell.execute_reply.started":"2023-10-25T09:45:49.452209Z","shell.execute_reply":"2023-10-25T09:45:49.464511Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def update_image_sizes(json_file, image_dir, out):\n    with open(json_file, encoding='utf-8') as f:\n        data = json.load(f)\n\n    for image in data['images']:\n        image_id = image['id']\n        image_path = image_dir + '/' + image_id + '.jpg'  # Chemin complet de l'image\n\n        # Ouvrir l'image avec PIL\n        img = PIL.Image.open(image_path)\n        width, height = img.size\n\n        # Mettre à jour les informations de taille dans le JSON\n        image['width'] = width\n        image['height'] = height\n\n    # Écrire le JSON mis à jour dans un nouveau fichier\n    with open(out, 'w') as outfile:\n        json.dump(data, outfile)\n\n    print(\"Mise à jour des tailles d'image terminée.\")\n    print(\"JSON mis à jour enregistré dans :\", \"gallica_dataset_file.json\")","metadata":{"id":"6F5figVFkqRB","execution":{"iopub.status.busy":"2023-10-25T09:45:49.466809Z","iopub.execute_input":"2023-10-25T09:45:49.467160Z","iopub.status.idle":"2023-10-25T09:45:49.477864Z","shell.execute_reply.started":"2023-10-25T09:45:49.467128Z","shell.execute_reply":"2023-10-25T09:45:49.476998Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#update_image_sizes(json_file, image_dir, \"gallica_dataset_file.json\")\n#update_image_sizes(json_file2, image_dir2, \"gallica_dataset_file2.json\")\n#update_image_sizes(json_file3, image_dir3, \"gallica_dataset_file3.json\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T09:45:49.479462Z","iopub.execute_input":"2023-10-25T09:45:49.480022Z","iopub.status.idle":"2023-10-25T09:45:49.493171Z","shell.execute_reply.started":"2023-10-25T09:45:49.479989Z","shell.execute_reply":"2023-10-25T09:45:49.492409Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"gallica_json = \"/kaggle/input/gallica-updated/gallica_dataset_file_all.json\"\n#gallica_json2 = \"/kaggle/input/gallica-updated/gallica_dataset_file2.json\"\n#gallica_json3 = \"/kaggle/input/gallica-updated/gallica_dataset_file3.json\"","metadata":{"execution":{"iopub.status.busy":"2023-10-25T09:45:49.494365Z","iopub.execute_input":"2023-10-25T09:45:49.494703Z","iopub.status.idle":"2023-10-25T09:45:49.504400Z","shell.execute_reply.started":"2023-10-25T09:45:49.494674Z","shell.execute_reply":"2023-10-25T09:45:49.503672Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import random\n\n#def get_my_dataset_dicts(json_file, category_dict,target_size = (800, 600)):\ndef get_my_dataset_dicts(json_file, category_dict, image_dir):\n    \"\"\"\n        from gallica Label Studio to COCO dataset json\n    \"\"\"\n    with open(json_file, encoding='utf-8') as f:\n        data = json.load(f)\n\n    dataset_dicts = []\n    for idx, image in enumerate(data['images']):\n        record = {}\n        # Create file path from local directory and image id\n        filename = os.path.join(image_dir, image['id'] + '.jpg')\n\n        # Assign image properties\n        record[\"file_name\"] = filename\n        record[\"height\"] = image[\"height\"] \n        record[\"width\"] = image[\"width\"]\n        record[\"image_id\"] = image['id']\n\n        annotations = []\n        # Assign annotations to image\n        for ann in data[\"annotations\"]:\n            for result in ann[\"result\"]:\n                if ann[\"id\"] == image[\"id\"] and type(result[\"label\"]) is not int and result[\"label\"][0] in category_dict.keys():\n                # Create a new dict for each annotation in the image\n                    x = int(result['bbox']['x'] / 100.0 * image[\"width\"])\n                    y = int(result['bbox']['y'] / 100.0 * image[\"height\"])\n                    width = int(result['bbox']['width'] / 100.0 * image[\"width\"])\n                    height = int(result['bbox']['height'] / 100.0 * image[\"height\"])\n                    obj = {\n                        \"bbox\": [x, y, width, height],\n                        \"bbox_mode\": BoxMode.XYWH_ABS,  # as your bounding box coordinates are in absolute format\n                        \"category_id\": category_dict[result[\"label\"][0]],  # map your label name to its corresponding id\n#                         \"id\": result[\"id\"],\n#                         \"iscrowd\": 0,\n#                         \"image_id\":ann[\"id\"],\n                    }\n                    annotations.append(obj)\n        record[\"annotations\"] = annotations\n        dataset_dicts.append(record)\n    return dataset_dicts\n\ndef mix_datasets(dataset1, dataset2, dataset3):\n    for data in dataset2:\n        dataset1.append(data)\n    for data in dataset3:\n        dataset1.append(data)\n    random.shuffle(dataset1)\n    return dataset1","metadata":{"id":"Svs4f5lyxtgY","execution":{"iopub.status.busy":"2023-10-25T09:45:49.505300Z","iopub.execute_input":"2023-10-25T09:45:49.505529Z","iopub.status.idle":"2023-10-25T09:45:49.518107Z","shell.execute_reply.started":"2023-10-25T09:45:49.505509Z","shell.execute_reply":"2023-10-25T09:45:49.517197Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\ndef remove_all_datasets():\n    registered_datasets = list(DatasetCatalog.list())\n    for dataset_name in registered_datasets:\n        DatasetCatalog.remove(dataset_name)\nremove_all_datasets()","metadata":{"id":"c9tghaVcbAUX","execution":{"iopub.status.busy":"2023-10-25T09:45:49.522467Z","iopub.execute_input":"2023-10-25T09:45:49.523098Z","iopub.status.idle":"2023-10-25T09:45:49.532494Z","shell.execute_reply.started":"2023-10-25T09:45:49.523072Z","shell.execute_reply":"2023-10-25T09:45:49.531624Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# PRINT DATASET\n\ndef print_coco_dataset(dataset):\n    my_dataset_metadata = MetadataCatalog.get(dataset)\n\n    # Get your dataset in Detectron2's format\n    dataset_dicts = DatasetCatalog.get(dataset)\n\n    for d in random.sample(dataset_dicts, 3):\n        # Open the image file\n        img = PIL.Image.open(d[\"file_name\"])\n        img = np.array(img)\n\n        # Handle grayscale images:\n        if len(img.shape) == 2:\n            img = np.stack([img] * 3, axis=-1)\n\n        # Create a visualizer instance\n        visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_metadata, scale=0.5)\n\n        # Draw the predictions on the image\n        vis = visualizer.draw_dataset_dict(d)\n\n        # Show the image using matplotlib\n        plt.imshow(vis.get_image()[:, :, ::-1])\n        plt.axis('off')\n        plt.show()\n","metadata":{"id":"cjMfeFbSC2vn","outputId":"87bf1262-9039-473c-e646-80c3d844adf0","execution":{"iopub.status.busy":"2023-10-25T09:45:49.533557Z","iopub.execute_input":"2023-10-25T09:45:49.533953Z","iopub.status.idle":"2023-10-25T09:45:49.544442Z","shell.execute_reply.started":"2023-10-25T09:45:49.533919Z","shell.execute_reply":"2023-10-25T09:45:49.543693Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def split_data(json_file, category_dict, image_dir, split='train'):\n    # Load json file\n    \"\"\"\n        Divide original dataset in train , val , test\n    \"\"\"\n    with open(json_file) as f:\n        data = json.load(f)\n\n    classes_count = np.zeros(len(category_dict))\n    # Convert to Detectron2 format\n    dataset_dicts = get_my_dataset_dicts(json_file, category_dict, image_dir)\n    print(len(dataset_dicts))\n    \n    #get total number of each classes\n    for data in dataset_dicts:        \n        for annotation in data[\"annotations\"]:\n            classes_count[annotation[\"category_id\"]] += 1\n    \n    data_train = []\n    data_val = []\n    data_test = []\n    data_lost = []\n    nb_image = 0\n    count = np.zeros(len(category_dict))\n    classes_count_sorted = np.argsort(classes_count)\n    for data in dataset_dicts:\n        isLost = True\n        for annotation in data[\"annotations\"]:\n            v = False\n            for i in range(len(category_dict)):\n                if count[annotation[\"category_id\"]] < classes_count[classes_count_sorted[i]]*0.83:\n                    data_train.append(data)\n                    for annotation in data[\"annotations\"]:\n                        count[annotation[\"category_id\"]] += 1\n                    nb_image+=1\n                    v=True\n                    break\n                elif count[annotation[\"category_id\"]] < classes_count[classes_count_sorted[i]]*0.95:\n                    data_val.append(data)\n                    for annotation in data[\"annotations\"]:\n                        count[annotation[\"category_id\"]] += 1\n                    nb_image+=1\n                    v=True\n                    break\n                elif count[annotation[\"category_id\"]] < classes_count[classes_count_sorted[i]]:\n                    data_test.append(data)\n                    for annotation in data[\"annotations\"]:\n                        count[annotation[\"category_id\"]] += 1\n                    nb_image+=1\n                    v=True\n                    break\n            if v:\n                isLost = False\n                break\n        if isLost:\n            data_lost.append(data)\n            \n    #append lost data to test data\n    for data in data_lost:\n        data_test.append(data)\n                        \n    print(\"count: \", count)\n    print(\"classes_count: \", classes_count)\n    print(\"nb_image: \", nb_image)\n    print(\"data_lost\", len(data_lost))\n    \n    return data_train, data_val, data_test\n    \n    #print(classes_count)\n    #print(np.argsort(classes_count))\ndatasets = split_data(gallica_json, category_dict, image_dir)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T09:45:49.546084Z","iopub.execute_input":"2023-10-25T09:45:49.546428Z","iopub.status.idle":"2023-10-25T09:45:57.088347Z","shell.execute_reply.started":"2023-10-25T09:45:49.546404Z","shell.execute_reply":"2023-10-25T09:45:57.087406Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"2738\ncount:  [ 650. 4410. 5598. 1557. 1038.   98.]\nclasses_count:  [ 650. 4410. 5598. 1557. 1038.   98.]\nnb_image:  2718\ndata_lost 20\n","output_type":"stream"}]},{"cell_type":"code","source":"def check_repartition(dataset):\n    classes_count = np.zeros(len(category_dict))\n    for data in dataset:\n        for annotation in data[\"annotations\"]:\n            classes_count[annotation[\"category_id\"]] += 1\n    return classes_count\ncheck_repartition(datasets[2])","metadata":{"execution":{"iopub.status.busy":"2023-10-25T09:45:57.089785Z","iopub.execute_input":"2023-10-25T09:45:57.090148Z","iopub.status.idle":"2023-10-25T09:45:57.100253Z","shell.execute_reply.started":"2023-10-25T09:45:57.090115Z","shell.execute_reply":"2023-10-25T09:45:57.099314Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([ 59., 354., 856., 117., 138.,   3.])"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport shutil\n\ntest_images = []\nfor i in range(len(datasets[2])):\n    test_images.append(datasets[2][i][\"image_id\"])\n\n\n# Define source and destination directories\nimage_dir = dataset_path + \"/image\"  # Your source directory\ndestination_dir = \"/kaggle/working/test_images\"  # Replace with your destination directory\n\n# Create the destination directory if it doesn't exist\nif not os.path.exists(destination_dir):\n    os.makedirs(destination_dir)\n\n# Iterate through the list of image filenames and copy them to the destination directory\nfor image_filename in test_images:\n    # Add the .jpg extension to the filenames\n    image_filename_with_extension = image_filename + \".jpg\"\n    \n    source_path = os.path.join(image_dir, image_filename_with_extension)\n    destination_path = os.path.join(destination_dir, image_filename_with_extension)\n    \n    try:\n        shutil.copy(source_path, destination_path)\n        print(f\"Successfully copied {image_filename} to {destination_dir}\")\n    except FileNotFoundError:\n        print(f\"File not found: {image_filename}\")\n    except FileExistsError:\n        print(f\"File already exists in the destination directory: {image_filename}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T09:45:57.101673Z","iopub.execute_input":"2023-10-25T09:45:57.102001Z","iopub.status.idle":"2023-10-25T09:46:01.213845Z","shell.execute_reply.started":"2023-10-25T09:45:57.101978Z","shell.execute_reply":"2023-10-25T09:46:01.212868Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Successfully copied 2df7c7a8-a476-4827-aed1-d7f613aba42b to /kaggle/working/test_images\nSuccessfully copied 13a8a57e-3017-497f-a3f3-0dd15abdf70f to /kaggle/working/test_images\nSuccessfully copied 6d1b71b9-0477-43d3-b997-050cf3fd79e6 to /kaggle/working/test_images\nSuccessfully copied ca7820d2-679a-4bb2-82b8-a2d5c9c9b2e4 to /kaggle/working/test_images\nSuccessfully copied de439109-a4bf-4b54-93a1-4a7381712bd4 to /kaggle/working/test_images\nSuccessfully copied c7452192-fc03-4614-858e-156a6254a4e3 to /kaggle/working/test_images\nSuccessfully copied d847c2e6-23ab-463b-91f8-c774da7122ab to /kaggle/working/test_images\nSuccessfully copied 41cd740c-935f-4213-9928-c719ae82dd11 to /kaggle/working/test_images\nSuccessfully copied 2de45329-04f6-494d-975a-71302836fe82 to /kaggle/working/test_images\nSuccessfully copied eb0ef928-3735-43a8-adef-4dd218f83c1a to /kaggle/working/test_images\nSuccessfully copied 62fff69c-f976-4d50-96d8-856cc50f99a4 to /kaggle/working/test_images\nSuccessfully copied 43ec59cb-2394-481d-8d2a-c2bade5f8e78 to /kaggle/working/test_images\nSuccessfully copied b55ca07a-f014-4df5-afec-89f7b96d45af to /kaggle/working/test_images\nSuccessfully copied 42a1fd42-7383-4f63-ba08-ff4efdaf8914 to /kaggle/working/test_images\nSuccessfully copied ac832164-33a8-4d2e-acb8-02fe7e8c66e9 to /kaggle/working/test_images\nSuccessfully copied 5bc573c1-b339-4921-901e-97d058b476a1 to /kaggle/working/test_images\nSuccessfully copied aee3e0a9-7c3e-494a-8091-81d1231e6264 to /kaggle/working/test_images\nSuccessfully copied 156d1606-69dc-413c-b797-39ce1b2b0f85 to /kaggle/working/test_images\nSuccessfully copied 67a07b78-f7cd-4768-9b12-b65dbc4a396c to /kaggle/working/test_images\nSuccessfully copied fb25a47c-ea66-40e7-bc02-bd209af3ee33 to /kaggle/working/test_images\nSuccessfully copied 8c33a743-15b5-4064-9976-d10ef46af845 to /kaggle/working/test_images\nSuccessfully copied 8ae17f93-bc7d-4b74-a5d1-870141203d71 to /kaggle/working/test_images\nSuccessfully copied e749781c-aeb5-4368-8720-2126624f8aa4 to /kaggle/working/test_images\nSuccessfully copied 94d5ecf0-6955-492d-bd6c-fa6e94a838da to /kaggle/working/test_images\nSuccessfully copied 4629b731-acfe-4a15-84a1-eb68fd5d1059 to /kaggle/working/test_images\nSuccessfully copied 7215ad62-612e-4465-b6bb-fac28bcf691b to /kaggle/working/test_images\nSuccessfully copied 06ed2f56-894d-4fd0-b6c3-ef313be6538b to /kaggle/working/test_images\nSuccessfully copied 0fc3b556-c7f2-4e57-8c54-b4a97a6a5728 to /kaggle/working/test_images\nSuccessfully copied f4cf62aa-2370-41d7-832c-63e564730e0c to /kaggle/working/test_images\nSuccessfully copied 7af2618a-2600-483b-ae2d-4867729549fe to /kaggle/working/test_images\nSuccessfully copied e233e91c-39e8-4b49-8647-fbd786cecbd6 to /kaggle/working/test_images\nSuccessfully copied 30c8b3c5-4653-4ff3-b663-643eb3671e00 to /kaggle/working/test_images\nSuccessfully copied e476ace9-1638-47fc-bfd3-2e3a25a1af6a to /kaggle/working/test_images\nSuccessfully copied f170022b-7e66-41fe-baa3-295808f31d45 to /kaggle/working/test_images\nSuccessfully copied 328389b7-b0c6-471e-a588-e172bac32fdb to /kaggle/working/test_images\nSuccessfully copied 86447ebf-8360-48be-ab8d-6da5a02d1072 to /kaggle/working/test_images\nSuccessfully copied 2c0dc819-21ca-44f6-9709-f971e31d708d to /kaggle/working/test_images\nSuccessfully copied 832914e6-aea2-4f41-a624-aedd1613d8f7 to /kaggle/working/test_images\nSuccessfully copied 44deb2fa-ef03-4a94-b87e-0e6a26931d3a to /kaggle/working/test_images\nSuccessfully copied b7c9e2a8-acfc-4df7-9726-8ae92ceaf97d to /kaggle/working/test_images\nSuccessfully copied 943587ff-a124-4638-874f-b05f2a42ed4d to /kaggle/working/test_images\nSuccessfully copied 8b6bbc1a-ca41-4681-a1ad-3d717466122e to /kaggle/working/test_images\nSuccessfully copied 814c68ce-f8b0-44a5-9e9c-108e9a7895e7 to /kaggle/working/test_images\nSuccessfully copied 409cd73e-bd48-4624-8ee8-14df53153d51 to /kaggle/working/test_images\nSuccessfully copied 91592aa2-949f-48f0-be50-05fe34ddb195 to /kaggle/working/test_images\nSuccessfully copied 6f8363de-0291-45a3-b216-06fba6844bd4 to /kaggle/working/test_images\nSuccessfully copied 2f88f79c-016b-4dfc-af87-99862ca6dd46 to /kaggle/working/test_images\nSuccessfully copied c4258a67-026d-4d24-affa-af5637ddf397 to /kaggle/working/test_images\nSuccessfully copied 328894fc-e058-462d-8c14-7bdf778a6657 to /kaggle/working/test_images\nSuccessfully copied fd1cd3be-557a-4bc0-a378-5b40721b7184 to /kaggle/working/test_images\nSuccessfully copied 2189e445-ed8f-40fb-89ba-6b74ee8f80d3 to /kaggle/working/test_images\nSuccessfully copied 1c91f15e-a4ae-4db0-8cf6-f690ead1c47d to /kaggle/working/test_images\nSuccessfully copied c7aa4ef2-7623-4dff-a490-13f029200043 to /kaggle/working/test_images\nSuccessfully copied b215c6a3-7adb-42ae-89f4-4b58e1b22751 to /kaggle/working/test_images\nSuccessfully copied 8d5a5753-4dc5-40c3-aa4a-e4872fe59118 to /kaggle/working/test_images\nSuccessfully copied da2129f4-d03e-43e7-b05f-70715cbf2d40 to /kaggle/working/test_images\nSuccessfully copied c1321e5e-4a75-4ea9-8641-7e18d731ade4 to /kaggle/working/test_images\nSuccessfully copied a2ac5f5e-a864-4d2d-807a-0015067fd331 to /kaggle/working/test_images\nSuccessfully copied 0fc90caf-3498-45d1-bd2b-1edc4129bd4e to /kaggle/working/test_images\nSuccessfully copied 7ebc43cb-2705-49d2-a187-4f11f60e5779 to /kaggle/working/test_images\nSuccessfully copied 6cb185e9-6753-45e9-a01e-89288b474810 to /kaggle/working/test_images\nSuccessfully copied 6628fbbc-3767-48eb-a8c7-ab037562b04e to /kaggle/working/test_images\nSuccessfully copied 739aa09a-7982-448d-9ea0-aae1417dfb31 to /kaggle/working/test_images\nSuccessfully copied 9342d1d0-fb9c-43a0-a466-88a80d3d5be3 to /kaggle/working/test_images\nSuccessfully copied 31c9945d-f897-49cd-8de1-72773c115fe1 to /kaggle/working/test_images\nSuccessfully copied 7405e7ed-6f73-4efa-9e5a-582311483dd4 to /kaggle/working/test_images\nSuccessfully copied 9376476a-1478-4e46-bb23-8c462c49e443 to /kaggle/working/test_images\nSuccessfully copied 926007ce-e561-483a-b470-c1511a2a0ff0 to /kaggle/working/test_images\nSuccessfully copied b1cf45df-be52-4c04-8d6c-a1eceec56cd8 to /kaggle/working/test_images\nSuccessfully copied e13a9417-9b72-4dd8-833f-8f196d7709bd to /kaggle/working/test_images\nSuccessfully copied 06debc31-4956-413f-9854-4ad79834236c to /kaggle/working/test_images\nSuccessfully copied 28af8572-66dc-4fe4-96f9-c6f400c6c506 to /kaggle/working/test_images\nSuccessfully copied b74696b7-0b06-49a0-9863-d2c63b591ef0 to /kaggle/working/test_images\nSuccessfully copied 8b855549-3494-454c-a87c-3fca2bb036ef to /kaggle/working/test_images\nSuccessfully copied 0be803d6-5fc9-4988-9d3a-e67dda03baf9 to /kaggle/working/test_images\nSuccessfully copied faf32f00-c0e3-4e49-99c5-1c157b8ee5c6 to /kaggle/working/test_images\nSuccessfully copied a2547ef2-00b0-47f9-9e6f-1014e92fb615 to /kaggle/working/test_images\nSuccessfully copied 5d443504-376d-441b-9166-76ca67fdfeb1 to /kaggle/working/test_images\nSuccessfully copied 978e2137-f7eb-4443-aac7-1e4c225cbf07 to /kaggle/working/test_images\nSuccessfully copied 2be6d482-6a9b-4167-ae29-8d255785ba41 to /kaggle/working/test_images\nSuccessfully copied 5fe5fb4e-4111-47d9-bc3c-7e4339cbb588 to /kaggle/working/test_images\nSuccessfully copied f5545bf5-10c7-426d-ae75-25dec86a58ef to /kaggle/working/test_images\nSuccessfully copied e5039a1c-5b1b-4cee-a9b5-c290cc1ca6d0 to /kaggle/working/test_images\nSuccessfully copied 19a02d62-c37b-4079-a4cd-cdb097e03e30 to /kaggle/working/test_images\nSuccessfully copied 92c9ba72-3d1a-479e-8bca-d86296d6e764 to /kaggle/working/test_images\nSuccessfully copied 10de3b43-863b-4992-8f6c-35897411e4c4 to /kaggle/working/test_images\nSuccessfully copied 0dde6b96-b5ce-4a48-ab29-39be24e973ca to /kaggle/working/test_images\nSuccessfully copied 61083970-45c2-4f60-b678-a86cd81d093d to /kaggle/working/test_images\nSuccessfully copied c3e988b4-3635-43b7-a5ec-3f14c2e98933 to /kaggle/working/test_images\nSuccessfully copied c21398a1-fc68-4e42-bd74-ca317c69a486 to /kaggle/working/test_images\nSuccessfully copied 8c4d35b7-d6ec-4733-af36-edd9a320b328 to /kaggle/working/test_images\nSuccessfully copied 9c2f4c66-a6fc-46b8-acf6-24f3ab8ba455 to /kaggle/working/test_images\nSuccessfully copied 4823cd57-3f00-4b50-8b14-c456935a758a to /kaggle/working/test_images\nSuccessfully copied 40bc6970-b137-4c8f-9e20-b787c314672e to /kaggle/working/test_images\nSuccessfully copied a3745c91-040e-47d1-b2f9-71a33e3b24ec to /kaggle/working/test_images\nSuccessfully copied 1c9a418d-dd59-43f6-bf1c-72763dfd6fd8 to /kaggle/working/test_images\nSuccessfully copied 5b034b89-cb22-4dfb-9b7d-c33ac357e6a5 to /kaggle/working/test_images\nSuccessfully copied 22ba4985-12c7-4c09-9318-aeb7aad3ff85 to /kaggle/working/test_images\nSuccessfully copied c6e44810-dda2-402c-a685-5d32f7e90cce to /kaggle/working/test_images\nSuccessfully copied 7884cf0c-74b9-4eee-81b6-8ce78062cb4b to /kaggle/working/test_images\nSuccessfully copied a0eae0aa-de26-493a-a2ae-29397e16e768 to /kaggle/working/test_images\nSuccessfully copied e149f702-8ac5-4650-a2cc-7296cee00b9e to /kaggle/working/test_images\nSuccessfully copied 8ef3ade2-ac00-40a7-889c-49885e58ccf0 to /kaggle/working/test_images\nSuccessfully copied 3e8d0d5f-f1d0-4481-b00f-1aa2a623a9ad to /kaggle/working/test_images\nSuccessfully copied 7571bfda-fc75-4d49-a09e-d71eb8c42a89 to /kaggle/working/test_images\nSuccessfully copied f0b90115-03dd-43c6-bfb4-6c540d5eaeea to /kaggle/working/test_images\nSuccessfully copied 86ff4d2a-12cb-48ab-851b-90ed5a75de75 to /kaggle/working/test_images\nSuccessfully copied 7c27cab0-9ee9-485d-aa88-e64158da15c8 to /kaggle/working/test_images\nSuccessfully copied a5aab339-5d30-405a-bc58-c396bc46002d to /kaggle/working/test_images\nSuccessfully copied 378b9fd3-ec81-4e2c-9e86-8792fc7a500b to /kaggle/working/test_images\nSuccessfully copied 5820cf38-918d-44f9-a8bc-33211f5b46fa to /kaggle/working/test_images\nSuccessfully copied a0fac49c-8565-4388-8bbb-878b54967ea0 to /kaggle/working/test_images\nSuccessfully copied 3f569cdc-ae4e-4b7d-a18e-20c15b2ebb42 to /kaggle/working/test_images\nSuccessfully copied a3dd93c7-f678-4d49-bff6-8bd0537177f1 to /kaggle/working/test_images\nSuccessfully copied a85c230a-273a-48dc-8f27-0ae9ba417edc to /kaggle/working/test_images\nSuccessfully copied df0a991c-a96a-41b0-811e-b26b4fd8218a to /kaggle/working/test_images\nSuccessfully copied c1881ea2-2c45-4728-b830-507e2d3ab965 to /kaggle/working/test_images\nSuccessfully copied b1479f35-c04d-4a65-9602-b45423cc1d2e to /kaggle/working/test_images\nSuccessfully copied 79a2c999-7412-47b9-95cc-81c55ea0f096 to /kaggle/working/test_images\nSuccessfully copied 600ae003-42fc-4f00-a9cc-86d15393c895 to /kaggle/working/test_images\nSuccessfully copied b7d518e2-cab1-4505-99e3-f38aa90b5f72 to /kaggle/working/test_images\nSuccessfully copied a74f9041-e85a-4e94-ba52-0783c9642911 to /kaggle/working/test_images\nSuccessfully copied 952ef2ba-cf18-4828-9ef6-c4699d7436c6 to /kaggle/working/test_images\nSuccessfully copied 2f443b64-83ac-4dd6-b1ce-8e11e2063b4e to /kaggle/working/test_images\nSuccessfully copied 5a093909-246e-44e8-bc73-0d43aa18503f to /kaggle/working/test_images\nSuccessfully copied da7c6bdf-1d4a-457c-9b0c-a48a9ae95fcf to /kaggle/working/test_images\nSuccessfully copied f7128c16-040c-42c1-aa62-8b2f8bf36007 to /kaggle/working/test_images\nSuccessfully copied 5c625f93-fb40-4ca7-b9d6-92ec25fa3d09 to /kaggle/working/test_images\nSuccessfully copied 11c2e5e0-fb9c-4451-8d7f-6101e828708c to /kaggle/working/test_images\nSuccessfully copied ae265536-bd1e-439a-817c-27523758bdba to /kaggle/working/test_images\nSuccessfully copied 79b71868-ddbb-4a2b-b7d7-505fa80332d6 to /kaggle/working/test_images\nSuccessfully copied a1d5faef-87e2-494e-9303-a9ab6512b3ea to /kaggle/working/test_images\nSuccessfully copied 3c201b29-b1e0-49d5-9b2c-5633e1e66087 to /kaggle/working/test_images\nSuccessfully copied ccb2c0cf-5cbb-48df-a14b-a07d5c373eb1 to /kaggle/working/test_images\nSuccessfully copied 1d72bcb0-52f6-487a-b6ec-1be9071e514c to /kaggle/working/test_images\nSuccessfully copied 9c6f5ab3-537a-456c-a333-2dc626a5fa07 to /kaggle/working/test_images\nSuccessfully copied ce10c05e-c686-4f8c-a740-15de3655651b to /kaggle/working/test_images\nSuccessfully copied 7e83830d-1a03-4364-9d8b-4dd2df395223 to /kaggle/working/test_images\nSuccessfully copied 7928bd0c-e9d4-46b0-84e5-b2017d2eddee to /kaggle/working/test_images\nSuccessfully copied 5ee72d72-7997-46aa-a8c3-8ed709c5eee3 to /kaggle/working/test_images\nSuccessfully copied 7986f8f9-ca9d-4e0d-8abd-adbc97b4f5a5 to /kaggle/working/test_images\nSuccessfully copied a1ee827f-f9ba-44e3-a7c0-6296b41ce211 to /kaggle/working/test_images\nSuccessfully copied ab441fd0-c53c-478e-8e33-a025564254dd to /kaggle/working/test_images\nSuccessfully copied 7ba23bdb-e81e-4d98-86a4-430328d83533 to /kaggle/working/test_images\nSuccessfully copied 600c73b8-111f-4c51-a374-252afe9ffb32 to /kaggle/working/test_images\nSuccessfully copied 39cdb05b-7379-4622-ac50-558d3096ad7a to /kaggle/working/test_images\nSuccessfully copied 634b07ec-a415-4eb0-abe4-3d0756f9d4aa to /kaggle/working/test_images\nSuccessfully copied 29c1f895-b75c-4d9b-909e-f4767d218736 to /kaggle/working/test_images\nSuccessfully copied 72d6e451-41bd-4efa-bf02-03da75d11701 to /kaggle/working/test_images\nSuccessfully copied 4c8b0eff-5366-49b2-9548-62f23b0206b7 to /kaggle/working/test_images\nSuccessfully copied cd0421ce-cb95-4d0a-8912-b623ffe089de to /kaggle/working/test_images\nSuccessfully copied 061fd36d-045e-45db-990e-32dfaa5eb57f to /kaggle/working/test_images\nSuccessfully copied b2a662a1-1498-4d03-819d-51049931b2ab to /kaggle/working/test_images\nSuccessfully copied e1f45be4-046e-4f66-994a-58e66378598c to /kaggle/working/test_images\nSuccessfully copied 1b307898-1a16-4aee-9dbf-c6fa502f04a5 to /kaggle/working/test_images\nSuccessfully copied e9d488ab-c3ed-450e-b9af-fb64e59ff35c to /kaggle/working/test_images\nSuccessfully copied 99b827ae-5eb8-487e-9868-952bb33ef2df to /kaggle/working/test_images\nSuccessfully copied 6d10532e-db45-41cd-8e67-c181e5cea880 to /kaggle/working/test_images\nSuccessfully copied 2f57525d-29cf-49ed-821e-71b514cf5550 to /kaggle/working/test_images\nSuccessfully copied c95fd29f-2e12-4e52-b54f-07cf6e3d080c to /kaggle/working/test_images\nSuccessfully copied 98ef3a12-5cc9-4b39-b5c5-0493911920d5 to /kaggle/working/test_images\nSuccessfully copied 44a5aba5-8b13-467d-9b48-ffb931c3ce10 to /kaggle/working/test_images\nSuccessfully copied 70550c11-db6a-4325-9ce4-253cfd5484b6 to /kaggle/working/test_images\nSuccessfully copied a51df17e-9ebc-47e1-bd9e-3a5c168db56b to /kaggle/working/test_images\nSuccessfully copied 4c754f1b-e5f6-4893-ad97-c889535cb969 to /kaggle/working/test_images\nSuccessfully copied 6e113934-79bd-4cc7-94e7-d108c49e14a7 to /kaggle/working/test_images\nSuccessfully copied c3826047-0d38-4f0a-a9c9-e78e93bf4ef6 to /kaggle/working/test_images\nSuccessfully copied 13d92d0d-9010-4f24-a1ed-be364708900e to /kaggle/working/test_images\nSuccessfully copied ac3594fe-ed7e-419d-9d39-2cf14a9356a3 to /kaggle/working/test_images\nSuccessfully copied a47e2db7-1764-41d9-9424-7b3d5c3725fb to /kaggle/working/test_images\nSuccessfully copied 87bca8d9-63a8-4e1f-8556-3cfd6edee228 to /kaggle/working/test_images\nSuccessfully copied f1693a1e-0e67-4f11-bba0-dfd7930d838a to /kaggle/working/test_images\nSuccessfully copied aea5f422-b8b0-4fe7-8dac-33f0331b19a0 to /kaggle/working/test_images\nSuccessfully copied e21a458e-8da6-4199-b186-bc021fb0a966 to /kaggle/working/test_images\nSuccessfully copied e796db15-4aac-43c9-a812-5c63129fb03c to /kaggle/working/test_images\nSuccessfully copied fecb88c3-0097-441e-a27e-02fd0135453c to /kaggle/working/test_images\nSuccessfully copied c780e898-b96c-4f49-a722-0192df2d9048 to /kaggle/working/test_images\nSuccessfully copied 6eb7bfc0-17d2-4cf9-bd2e-81228903b223 to /kaggle/working/test_images\nSuccessfully copied 33623fe2-b960-42ce-9bc9-0c19d5373be4 to /kaggle/working/test_images\nSuccessfully copied 896ffce9-bc9f-4786-b84d-5bc421f1ee71 to /kaggle/working/test_images\nSuccessfully copied f933386c-867f-411d-bf3f-3529cffe362d to /kaggle/working/test_images\nSuccessfully copied c0eaf583-32d7-497f-8dac-df959f9d7ddc to /kaggle/working/test_images\nSuccessfully copied af5d7d81-895d-4376-9e05-330f72d8ab66 to /kaggle/working/test_images\nSuccessfully copied 3c263b44-8b72-403f-ab43-db6930c83c36 to /kaggle/working/test_images\nSuccessfully copied 2b3a8015-2f78-4f37-bc9f-295f008ed5d7 to /kaggle/working/test_images\nSuccessfully copied f91400bd-5f77-4532-aca8-fc398d111803 to /kaggle/working/test_images\nSuccessfully copied 5fdd30e4-e4ec-4bda-842c-aaed52fb08e0 to /kaggle/working/test_images\nSuccessfully copied 5f84a46e-a568-462f-8476-35866b41d2ff to /kaggle/working/test_images\nSuccessfully copied 249009f7-2dfa-4dcf-a68d-49d4d51fb8f8 to /kaggle/working/test_images\nSuccessfully copied 1261948e-3377-40b3-ab08-4356739255c6 to /kaggle/working/test_images\nSuccessfully copied 33fec9d4-9521-4ceb-8d4c-4360309c666e to /kaggle/working/test_images\nSuccessfully copied 71513e5a-2c9c-4b16-b502-1fba59bb873f to /kaggle/working/test_images\nSuccessfully copied 8d89e7c4-ebfa-4597-a044-99fc45072ddb to /kaggle/working/test_images\nSuccessfully copied 70a0f09e-427a-40d8-8c7e-06a37e5c6cc7 to /kaggle/working/test_images\nSuccessfully copied dcb6bf88-3b35-4c28-8d71-95dd77fa96ad to /kaggle/working/test_images\nSuccessfully copied dda3a5a8-fd4e-4d30-ae38-3fb79f326dd4 to /kaggle/working/test_images\nSuccessfully copied cbf1099c-884b-4baf-b666-3f2f74d936e6 to /kaggle/working/test_images\nSuccessfully copied 653c81fd-0694-4abc-9991-4833304d91eb to /kaggle/working/test_images\nSuccessfully copied 77847850-00b0-4c7a-8c7e-c85f5f06e1f5 to /kaggle/working/test_images\nSuccessfully copied dc61c31f-9f5d-4fe7-ac1f-a0740b4c7985 to /kaggle/working/test_images\nSuccessfully copied 5a3a5b81-4b86-445d-baa1-15a7c6e643ec to /kaggle/working/test_images\nSuccessfully copied b0b06f0e-9063-466f-8051-1c5d7d46b266 to /kaggle/working/test_images\nSuccessfully copied cd8e172f-84de-4c55-8e99-bb3601b53cdf to /kaggle/working/test_images\nSuccessfully copied 58c333c3-9f04-4c85-836b-16bee065bf9e to /kaggle/working/test_images\nSuccessfully copied 31c19176-187f-4a92-aced-541ef17d5fbb to /kaggle/working/test_images\nSuccessfully copied d3918aa9-ac12-4e9e-9e73-3a016d7e3eac to /kaggle/working/test_images\nSuccessfully copied e88c1c8c-88d5-48f6-8ab1-7f657f880847 to /kaggle/working/test_images\nSuccessfully copied 42589413-8318-4410-b653-0e94b30b801b to /kaggle/working/test_images\nSuccessfully copied 6e53070f-4cda-46f9-833a-2d1963dfc2a3 to /kaggle/working/test_images\nSuccessfully copied f234b6bf-eb37-442e-8f26-aeafecff8237 to /kaggle/working/test_images\nSuccessfully copied 86148099-fa01-49f0-ac4c-ff37351abaa2 to /kaggle/working/test_images\nSuccessfully copied 4ce77a2a-b9c4-429c-b5d7-eba9c1c9c610 to /kaggle/working/test_images\nSuccessfully copied c4dbddb6-4c8b-4a0d-8df1-584a607fca82 to /kaggle/working/test_images\nSuccessfully copied 45b4621a-7529-4128-ab6f-4fb7dbcdf318 to /kaggle/working/test_images\nSuccessfully copied aa0688cc-171f-4ecf-897b-3f3406252788 to /kaggle/working/test_images\nSuccessfully copied 6a6925ac-5ad8-4829-a88f-0109293e3cd3 to /kaggle/working/test_images\nSuccessfully copied 02adbf5a-4029-486e-ab4e-c955fbfc0326 to /kaggle/working/test_images\nSuccessfully copied e9292297-7e61-41d8-9d24-dc9f7ed90eea to /kaggle/working/test_images\nSuccessfully copied 58cf781f-5b2e-4e32-aedc-d9b1cd87ddc0 to /kaggle/working/test_images\nSuccessfully copied 5418b343-5660-41b1-b870-8af2779e9419 to /kaggle/working/test_images\nSuccessfully copied c7408144-7754-44f4-9128-4d20adc579d4 to /kaggle/working/test_images\nSuccessfully copied dca3a106-7ffb-4f91-9b05-c8e4828f623e to /kaggle/working/test_images\nSuccessfully copied 930da2f9-2ec8-45b3-9814-f69347ec70fe to /kaggle/working/test_images\nSuccessfully copied e3e4297b-2a53-460e-906f-485bc0f1b788 to /kaggle/working/test_images\nSuccessfully copied 81bffbf3-aed2-4450-91ec-9213865b3705 to /kaggle/working/test_images\nSuccessfully copied 99bbe413-8ef6-4b53-a709-ae9d031c727c to /kaggle/working/test_images\nSuccessfully copied f436c7c6-db4f-477c-bbd8-3b3ce723cfa0 to /kaggle/working/test_images\nSuccessfully copied 99296a28-9b3a-4b06-a930-c8549404d715 to /kaggle/working/test_images\nSuccessfully copied a0c5e4ef-8b74-4627-81cc-22917dff4474 to /kaggle/working/test_images\nSuccessfully copied 8afda03c-0b47-4a9e-983e-46120741a586 to /kaggle/working/test_images\nSuccessfully copied 47ef5432-91c7-4709-867d-bb66d7492e0a to /kaggle/working/test_images\nSuccessfully copied c085cc61-9844-4ac5-8008-b560bef50acd to /kaggle/working/test_images\nSuccessfully copied 6aeb040d-a74f-46b4-ac37-2f48ca6f1cba to /kaggle/working/test_images\nSuccessfully copied fca2f67b-71d4-4105-ac3d-fbc2615a504b to /kaggle/working/test_images\nSuccessfully copied 78b5c94d-5493-4944-858f-9fcfc870940a to /kaggle/working/test_images\nSuccessfully copied 840f76a3-788d-4a7d-9916-f469194be3d7 to /kaggle/working/test_images\nSuccessfully copied ff012ff5-7c46-42ee-bdf7-91709f546807 to /kaggle/working/test_images\nSuccessfully copied 059e651d-0647-4410-8028-3660457dc17a to /kaggle/working/test_images\nSuccessfully copied 3d6fcccd-0d46-4a90-8dce-09b3a899076d to /kaggle/working/test_images\nSuccessfully copied c1451d5c-6881-4b8b-a2c9-0ac42af8977f to /kaggle/working/test_images\nSuccessfully copied 468f92ee-71a8-469e-9783-ef54587da0c5 to /kaggle/working/test_images\nSuccessfully copied f2ddba8f-3c84-4bb7-b6e4-bfd7a1f99172 to /kaggle/working/test_images\nSuccessfully copied cde66f94-85cb-4ee5-ade2-794138cf55b1 to /kaggle/working/test_images\nSuccessfully copied 2008d937-ce64-4bc0-9080-b925475e0090 to /kaggle/working/test_images\nSuccessfully copied 428b3c8b-f008-4d1b-b792-9290a6deff60 to /kaggle/working/test_images\nSuccessfully copied ca621556-1ac6-4ccd-886e-3b0e99261c18 to /kaggle/working/test_images\nSuccessfully copied 401e2454-98be-4a6b-adc5-ece5adb9550f to /kaggle/working/test_images\nSuccessfully copied 50b0aa92-2396-41e1-9848-4dc0a37b770a to /kaggle/working/test_images\nSuccessfully copied 4c1a029c-0c23-4e92-af47-f9a981a85d34 to /kaggle/working/test_images\nSuccessfully copied e0188fe7-a31d-4510-9c2a-9c011cf71b4f to /kaggle/working/test_images\nSuccessfully copied 6e9b9467-444c-4611-841c-ed7ffdf06b78 to /kaggle/working/test_images\nSuccessfully copied eb3c2cd9-2233-4eac-9360-ebb86574164d to /kaggle/working/test_images\nSuccessfully copied b66f2dd7-a61b-40c0-8549-408fdce77668 to /kaggle/working/test_images\nSuccessfully copied 2a7898f3-b1ae-4bd1-94d0-315aea21eb34 to /kaggle/working/test_images\nSuccessfully copied 830e9453-6bfe-4174-82d7-f28e01653f57 to /kaggle/working/test_images\nSuccessfully copied 4d23c1f0-3ec8-42f6-878b-324887e418e3 to /kaggle/working/test_images\nSuccessfully copied 0e17641f-51e1-4ca5-b30f-808b58a42403 to /kaggle/working/test_images\nSuccessfully copied 5e83fac1-3cbe-45c1-9b35-608358f471ac to /kaggle/working/test_images\nSuccessfully copied a9460e05-5709-4e20-9df7-6554f5b49c16 to /kaggle/working/test_images\n","output_type":"stream"}]},{"cell_type":"code","source":"zip_file_name = \"images.zip\"\n\n# Zip the destination directory\nshutil.make_archive(destination_dir, 'zip', destination_dir)\n\n# Rename the generated archive to the desired name\nos.rename(destination_dir + '.zip', zip_file_name)\nprint(f\"Successfully zipped the directory as {zip_file_name}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T09:46:01.215615Z","iopub.execute_input":"2023-10-25T09:46:01.216059Z","iopub.status.idle":"2023-10-25T09:46:09.906879Z","shell.execute_reply.started":"2023-10-25T09:46:01.216010Z","shell.execute_reply":"2023-10-25T09:46:09.905961Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Successfully zipped the directory as images.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(datasets[0])/2738*100)\nprint(len(datasets[1])/2738*100)\nprint(len(datasets[2])/2738*100)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T09:46:09.908063Z","iopub.execute_input":"2023-10-25T09:46:09.908348Z","iopub.status.idle":"2023-10-25T09:46:09.913545Z","shell.execute_reply.started":"2023-10-25T09:46:09.908323Z","shell.execute_reply":"2023-10-25T09:46:09.912688Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"70.12417823228634\n20.4163623082542\n9.45945945945946\n","output_type":"stream"}]},{"cell_type":"code","source":"random.seed(142)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset_dicts_split(datasets, split='train'):\n    # Load json file\n    \"\"\"\n        Divide original dataset in train , val , test\n    \"\"\"\n    random.seed(42)\n    # Shuffle data\n    random.shuffle(datasets[0])\n    random.shuffle(datasets[1])\n    random.shuffle(datasets[2])\n\n    if split == 'train':\n        return datasets[0]\n    elif split == 'val':\n        return datasets[1]\n    elif split == 'test':\n        return datasets[2]","metadata":{"id":"s7dtpc1yM8ZH","execution":{"iopub.status.busy":"2023-10-25T10:21:16.089047Z","iopub.status.idle":"2023-10-25T10:21:16.089380Z","shell.execute_reply.started":"2023-10-25T10:21:16.089218Z","shell.execute_reply":"2023-10-25T10:21:16.089234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#gallica_json = \"/kaggle/working/gallica_dataset_file.json\"\nremove_all_datasets()\nfor d in [\"train\", \"val\", \"test\"]:\n    #DatasetCatalog.register(\"my_dataset_\" + d, lambda d=d: get_dataset_dicts_split(json_file, category_dict, d))\n    #MetadataCatalog.get(\"my_dataset_\" + d).set(thing_classes=list(category_dict.keys()))\n    DatasetCatalog.register(\"my_dataset_\" + d, lambda d=d: get_dataset_dicts_split(datasets, d))\n    MetadataCatalog.get(\"my_dataset_\" + d).set(thing_classes=list(category_dict.keys()))","metadata":{"id":"PvatQwEjM_pv","execution":{"iopub.status.busy":"2023-10-25T10:21:16.090569Z","iopub.status.idle":"2023-10-25T10:21:16.090951Z","shell.execute_reply.started":"2023-10-25T10:21:16.090779Z","shell.execute_reply":"2023-10-25T10:21:16.090801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_coco_dataset(\"my_dataset_val\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.092819Z","iopub.status.idle":"2023-10-25T10:21:16.093156Z","shell.execute_reply.started":"2023-10-25T10:21:16.092987Z","shell.execute_reply":"2023-10-25T10:21:16.093003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.engine import DefaultTrainer\nfrom detectron2.config import get_cfg\nfrom detectron2.data import build_detection_train_loader,  DatasetMapper\nfrom detectron2.data.transforms import ResizeShortestEdge, RandomFlip\n","metadata":{"id":"oPEULXunNXTu","execution":{"iopub.status.busy":"2023-10-25T10:21:16.094503Z","iopub.status.idle":"2023-10-25T10:21:16.094864Z","shell.execute_reply.started":"2023-10-25T10:21:16.094669Z","shell.execute_reply":"2023-10-25T10:21:16.094685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = get_cfg()\n\n\n# Specify the model to use\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n\n# Override the dataset and solver settings\ncfg.DATASETS.TRAIN = (\"my_dataset_train\",)\ncfg.DATASETS.TEST = (\"my_dataset_val\",)\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS =  model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.000005  # pick a good learning rate\ncfg.SOLVER.MAX_ITER = 3000    # adjust up if val mAP is still rising, adjust down if overfit\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 300   # faster, and good enough for this dataset\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(category_dict)  # number of classes in your dataset","metadata":{"id":"g89tPNyKNZes","execution":{"iopub.status.busy":"2023-10-25T10:21:16.096130Z","iopub.status.idle":"2023-10-25T10:21:16.096459Z","shell.execute_reply.started":"2023-10-25T10:21:16.096299Z","shell.execute_reply":"2023-10-25T10:21:16.096315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.data import transforms as T","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.097773Z","iopub.status.idle":"2023-10-25T10:21:16.098089Z","shell.execute_reply.started":"2023-10-25T10:21:16.097935Z","shell.execute_reply":"2023-10-25T10:21:16.097949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Spécifiez les augmentations que vous souhaitez utiliser\ncfg.INPUT.CROP.ENABLED = True\ncfg.INPUT.CROP.SIZE = [0.8, 0.8]\n\n# Utilisez une augmentation standard de Detectron 2 ou définissez la vôtre\naugmentation = [\n    T.RandomBrightness(0.5, 2.0),\n    T.RandomContrast(0.5, 2.0),\n    T.RandomSaturation(0.5, 2.0),\n    T.RandomRotation(angle=[0, 360], expand=True),\n    T.RandomFlip(),\n]\n\ncfg.INPUT.AUGMENTATION = augmentation\n","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.099788Z","iopub.status.idle":"2023-10-25T10:21:16.100094Z","shell.execute_reply.started":"2023-10-25T10:21:16.099943Z","shell.execute_reply":"2023-10-25T10:21:16.099957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg)\ntrainer.resume_or_load(resume=False)\n\n# Measure the training time\nstart_time = time.time()\ntrainer.train()\nend_time = time.time()\n\n# Calculate the elapsed time\nelapsed_time = end_time - start_time\n\nprint(\"Training time: {:.4f} seconds\".format(elapsed_time))","metadata":{"id":"k5lDusLrNfZ0","outputId":"f27922df-fe8d-4be3-820e-71badee44770","execution":{"iopub.status.busy":"2023-10-25T10:21:16.101513Z","iopub.status.idle":"2023-10-25T10:21:16.101892Z","shell.execute_reply.started":"2023-10-25T10:21:16.101691Z","shell.execute_reply":"2023-10-25T10:21:16.101707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.evaluation import COCOEvaluator, inference_on_dataset, COCOPanopticEvaluator\nfrom detectron2.data import build_detection_test_loader\nfrom detectron2.data import MetadataCatalog\n\n# Get the metadata for your dataset\nmy_dataset_metadata = MetadataCatalog.get(\"my_dataset_val\")\n\n# Create an evaluator for the validation set\nevaluator = COCOEvaluator(\"my_dataset_val\", output_dir=\"./output\")\n\n# Create a test data loader\ntest_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n\n# Perform inference on the validation set\ntry:\n    results = inference_on_dataset(trainer.model, test_loader, evaluator)\nexcept Exception as e:\n    # Print the error message\n    print(\"Error:\", str(e))\n    \n    # Get the current image ID\n    #img_id = test_loader.dataset.get_img_info(0)[\"id\"]\n    # Print the image ID where the error occurred\n    #print(\"Image ID:\", img_id)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.103080Z","iopub.status.idle":"2023-10-25T10:21:16.103426Z","shell.execute_reply.started":"2023-10-25T10:21:16.103264Z","shell.execute_reply":"2023-10-25T10:21:16.103281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.utils.visualizer import ColorMode\nfrom detectron2.engine import DefaultPredictor\n\n\n#Use the final weights generated after successful training for inference  \ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8  # set the testing threshold for this model\n#Pass the validation dataset\ncfg.DATASETS.TEST = (\"my_dataset_val\", )\n\npredictor = DefaultPredictor(cfg)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.104354Z","iopub.status.idle":"2023-10-25T10:21:16.104649Z","shell.execute_reply.started":"2023-10-25T10:21:16.104500Z","shell.execute_reply":"2023-10-25T10:21:16.104514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from detectron2.checkpoint import DetectionCheckpointer, Checkpointer\n\ncheckpointer = DetectionCheckpointer(trainer.model, save_dir=cfg.OUTPUT_DIR)\ncheckpointer.save(\"my_model\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.106041Z","iopub.status.idle":"2023-10-25T10:21:16.106348Z","shell.execute_reply.started":"2023-10-25T10:21:16.106198Z","shell.execute_reply":"2023-10-25T10:21:16.106212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_dicts = DatasetCatalog.get(\"my_dataset_test\")\nmetadata = MetadataCatalog.get(\"my_dataset_test\")\nfile_names = [\"5f84a46e-a568-462f-8476-35866b41d2ff\",\n\"6a6925ac-5ad8-4829-a88f-0109293e3cd3\",\n\"13a8a57e-3017-497f-a3f3-0dd15abdf70f\",\n\"67a07b78-f7cd-4768-9b12-b65dbc4a396c\",\n\"a5aab339-5d30-405a-bc58-c396bc46002d\"]\n\ndataset_test = []\nfor data in dataset_dicts:\n    if data[\"image_id\"] in file_names:\n        dataset_test.append(data)\n\nfor d in dataset_test:\n    im = cv2.imread(d[\"file_name\"])\n\n    # Make predictions\n    outputs = predictor(im)\n\n    # Visualize both ground truth and predictions\n    visualizer_pred = Visualizer(\n        im[:, :, ::-1], metadata=metadata, scale=0.8, instance_mode=ColorMode.IMAGE\n    )\n    visualizer_gt = Visualizer(\n        im[:, :, ::-1], metadata=metadata, scale=0.8, instance_mode=ColorMode.IMAGE\n    )\n\n\n    # Draw ground truth bounding boxes\n    gt_visualized = visualizer_gt.draw_dataset_dict(d)\n\n    # Draw instance predictions\n    predictions_visualized = visualizer_pred.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n\n\n    # Combine the images horizontally\n    final_image = np.concatenate((gt_visualized.get_image()[:, :, ::-1], predictions_visualized.get_image()[:, :, ::-1]), axis=1)\n    \n    # Assuming you have final_image generated\n    final_image_bgr = final_image[:, :, ::-1]  # Convert to BGR format\n\n    if not os.path.exists(\"/kaggle/working/predictions\"):\n        os.makedirs(\"/kaggle/working/predictions\")\n    \n    # Save the image to a file (e.g., final_image.png)\n    cv2.imwrite('/kaggle/working/predictions/'+d[\"image_id\"]+'.png', final_image_bgr)\n\n    # Show the combined image using matplotlib\n    plt.imshow(final_image)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.108011Z","iopub.status.idle":"2023-10-25T10:21:16.108385Z","shell.execute_reply.started":"2023-10-25T10:21:16.108200Z","shell.execute_reply":"2023-10-25T10:21:16.108219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"zip_file_name = \"predictions.zip\"\n\n# Zip the destination directory\nshutil.make_archive(\"/kaggle/working/predictions/\", 'zip', \"/kaggle/working/predictions/\")\n\n# Rename the generated archive to the desired name\nos.rename(\"/kaggle/working/predictions/\" + '.zip', zip_file_name)\nprint(f\"Successfully zipped the directory as {zip_file_name}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.110077Z","iopub.status.idle":"2023-10-25T10:21:16.110408Z","shell.execute_reply.started":"2023-10-25T10:21:16.110243Z","shell.execute_reply":"2023-10-25T10:21:16.110258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_directory(path):\n    n = 0\n    for file_name in os.listdir(path):\n        if n >= 5:\n            break\n        # Read the image\n        file_path = os.path.join(path, file_name)\n        im = cv2.imread(file_path)\n\n        # Measure the prediction time\n        start_time = time.time()\n        outputs = predictor(im)\n        end_time = time.time()\n        \n        # Calculate the elapsed time\n        elapsed_time = end_time - start_time\n\n        print(\"Inference time: {:.4f} seconds, shape of {}\".format(elapsed_time, im.shape))\n        \n        # Extract the instance masks and their associated classes\n        instances = outputs[\"instances\"].to(\"cpu\")\n        #instance_masks = instances.pred_masks.numpy()\n        print(instances.pred_boxes.tensor.tolist())\n        print(instances.pred_classes.tolist())\n\n        # Visualize the predictions\n        v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8, instance_mode=ColorMode.IMAGE)\n        v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n\n        # Display the image\n        plt.imshow(v.get_image()[:, :, ::-1])\n        plt.axis('off')\n        plt.show()\n        n+=1\n        \npredict_directory(\"/kaggle/input/dataset2/dataset2/1418\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.111420Z","iopub.status.idle":"2023-10-25T10:21:16.111884Z","shell.execute_reply.started":"2023-10-25T10:21:16.111630Z","shell.execute_reply":"2023-10-25T10:21:16.111659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m pip install coco-pano-ext-demo","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.113568Z","iopub.status.idle":"2023-10-25T10:21:16.113908Z","shell.execute_reply.started":"2023-10-25T10:21:16.113720Z","shell.execute_reply":"2023-10-25T10:21:16.113734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = (400,400)\n\ndef create_mask_with_json(data, width, height):\n    masks = [np.zeros(img_size, dtype=np.uint8) for x in range(len(category_dict))]\n    #mask = np.zeros(img_size, dtype=np.uint8)\n    for annotation in data[\"annotations\"]:\n        # Convert annotation units to pixel values\n        x = int(annotation['bbox'][0])\n        y = int(annotation['bbox'][1])\n        x2 = int(annotation['bbox'][2])\n        y2 = int(annotation['bbox'][3])\n        \n        # Scale the coordinates to match the mask size\n        x_scaled = int(x * img_size[1] / width)      # New x-coordinate after scaling\n        y_scaled = int(y * img_size[0] / height)     # New y-coordinate after scaling\n        width_scaled = int(x2 * img_size[1] / width)    # New width after scaling\n        height_scaled = int(y2 * img_size[0] / height)  # New height after scaling\n        \n\n        # Assign the corresponding label value to the pixels within the scaled bounding box\n        masks[annotation[\"category_id\"]][y_scaled:y_scaled+height_scaled, x_scaled:x_scaled+width_scaled] = 1\n        \n    return np.array(masks)\n\ndef create_mask_with_prediction(boxes, classes, width, height):\n    masks = [np.zeros(img_size, dtype=np.uint8) for x in range(len(category_dict))]\n    for i in range(len(boxes)):\n        # Convert annotation units to pixel values\n        x = int(boxes[i][0])\n        y = int(boxes[i][1])\n        x2 = int(boxes[i][2])\n        y2 = int(boxes[i][3])\n\n        # Scale the coordinates to match the mask size\n        x_scaled = int(x * img_size[1] / width)      # New x-coordinate after scaling\n        y_scaled = int(y * img_size[0] / height)     # New y-coordinate after scaling\n        width_scaled = int(x2 * img_size[1] / width)    # New width after scaling\n        height_scaled = int(y2 * img_size[0] / height)  # New height after scaling\n\n        # Assign the corresponding label value to the pixels within the scaled bounding box\n        masks[classes[i]][y_scaled:height_scaled, x_scaled:width_scaled] = 1\n    \n    return np.array(masks)\n\ndef predict_image(path):\n    # Read the image\n    im = cv2.imread(path)\n\n    # Perform prediction\n    outputs = predictor(im)\n\n    # Extract the instance masks and their associated classes\n    instances = outputs[\"instances\"].to(\"cpu\")\n\n    return (instances.pred_boxes.tensor.tolist(),instances.pred_classes.tolist()) \n        \n    \ngroundtruth = []\npredictions = []\nfor data in dataset_dicts:\n    groundtruth.append(create_mask_with_json(data, data[\"width\"], data[\"height\"]))\n    prediction = predict_image(data[\"file_name\"])\n    predictions.append(create_mask_with_prediction(prediction[0], prediction[1], data[\"width\"], data[\"height\"]))","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.114808Z","iopub.status.idle":"2023-10-25T10:21:16.115109Z","shell.execute_reply.started":"2023-10-25T10:21:16.114957Z","shell.execute_reply":"2023-10-25T10:21:16.114971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(groundtruth).shape","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.116240Z","iopub.status.idle":"2023-10-25T10:21:16.116564Z","shell.execute_reply.started":"2023-10-25T10:21:16.116406Z","shell.execute_reply":"2023-10-25T10:21:16.116422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.array(groundtruth)[:,1].shape","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.118031Z","iopub.status.idle":"2023-10-25T10:21:16.118468Z","shell.execute_reply.started":"2023-10-25T10:21:16.118240Z","shell.execute_reply":"2023-10-25T10:21:16.118261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.all(groundtruth[0][1]==0)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.119903Z","iopub.status.idle":"2023-10-25T10:21:16.120343Z","shell.execute_reply.started":"2023-10-25T10:21:16.120113Z","shell.execute_reply":"2023-10-25T10:21:16.120134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef show_pred(n, class_predicted=1):\n    truth = []\n    for annotation in dataset_dicts[n][\"annotations\"]:\n        l = annotation['bbox'].copy()\n        l[2] += l[0]\n        l[3] += l[1]\n        truth.append(l)\n    print(\"groundtruth: \", truth)\n    # Read the image\n    im = cv2.imread(dataset_dicts[n][\"file_name\"])\n\n    # Perform prediction\n    outputs = predictor(im)\n\n    # Extract the instance masks and their associated classes\n    instances = outputs[\"instances\"].to(\"cpu\")\n    #instance_masks = instances.pred_masks.numpy()\n    print(\"prediction: \", instances.pred_boxes.tensor.tolist())\n\n    # Visualize the predictions\n    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8, instance_mode=ColorMode.IMAGE)\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n\n    # Display the image\n    plt.imshow(v.get_image()[:, :, ::-1])\n    plt.axis('off')\n    plt.show()\n    \n    plt.imshow(groundtruth[n][class_predicted], cmap='binary')  # 'binary' colormap for black and white\n    plt.title('Binary Map')\n    #plt.colorbar()  # Add a colorbar to show the values\n    plt.show()\n\n    plt.imshow(predictions[n][class_predicted], cmap='binary')  # 'binary' colormap for black and white\n    plt.title('Binary Map')\n    #plt.colorbar()  # Add a colorbar to show the values\n    plt.show()\n\nshow_pred(0, 2)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.121920Z","iopub.status.idle":"2023-10-25T10:21:16.122253Z","shell.execute_reply.started":"2023-10-25T10:21:16.122086Z","shell.execute_reply":"2023-10-25T10:21:16.122102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from coco_pano_ext_demo import COCO_plot, COCO\nfrom coco_pano_ext_demo.coco import _compute_labelmap, _compute_iou\nfrom coco_pano_ext_demo.iou import compute_matching_scores","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.123580Z","iopub.status.idle":"2023-10-25T10:21:16.123940Z","shell.execute_reply.started":"2023-10-25T10:21:16.123741Z","shell.execute_reply":"2023-10-25T10:21:16.123776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_matching_weights(target_binary_image, pred_binary_image) -> tuple[list[float], list[float]]:\n    # extract connected components\n    T = _compute_labelmap(target_binary_image)\n    P = _compute_labelmap(pred_binary_image)\n    # computes IoUs\n    wtp, wpt = 0,0#_compute_iou(T, P)\n    if np.all(pred_binary_image==0):\n        wtp, wpt = _compute_iou(T, T)\n    elif np.all(target_binary_image==0):\n        wtp, wpt = _compute_iou(P, P)\n    else:\n        wtp, wpt = _compute_iou(T, P)\n    # remove background components\n    wtp, wpt = wtp[1:], wpt[1:]\n    return wtp, wpt","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.125582Z","iopub.status.idle":"2023-10-25T10:21:16.126049Z","shell.execute_reply.started":"2023-10-25T10:21:16.125818Z","shell.execute_reply":"2023-10-25T10:21:16.125839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Iterable\nimport pandas as pd\ndef compute_pq_score_list_single_class(targets: Iterable[np.ndarray], predictions: Iterable[np.ndarray]) -> tuple[float, float, float, pd.DataFrame]:\n    # Init global accumulators\n    W_TtoP_global = []\n    W_PtoT_global = []\n    # loop over predictions (single class, TODO repeat for each class)\n    for T0, P0 in zip(targets, predictions):\n        # Compute pairwise matching scores, exluding background\n        wtp, wpt = compute_matching_weights(T0, P0)\n        # Update global matching lists\n        W_TtoP_global.extend(wtp.tolist())\n        W_PtoT_global.extend(wpt.tolist())\n    # report final score\n    pairing_threshold = 0.5\n    df = compute_matching_scores(np.array(W_TtoP_global), np.array(W_PtoT_global), pairing_threshold)\n    COCO_SQ = df[\"IoU\"].mean() if len(df) > 0 else 0\n    COCO_RQ = df[\"F-score\"].iloc[0] if len(df) > 0 else 0\n    COCO_PQ = COCO_SQ * COCO_RQ\n    \n    return COCO_PQ, COCO_RQ, COCO_SQ, df","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.127251Z","iopub.status.idle":"2023-10-25T10:21:16.127698Z","shell.execute_reply.started":"2023-10-25T10:21:16.127462Z","shell.execute_reply":"2023-10-25T10:21:16.127483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get the average iou of the predictions\nscores_per_class = np.zeros(len(category_dict))\n\nfor i in range(len(category_dict)):\n    T = np.array(groundtruth)[:,i]\n    P = np.array(predictions)[:,i]\n    scores_per_class[i], COCO_RQ, COCO_SQ, df = compute_pq_score_list_single_class(T, P)\n\nscores_per_class","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.084246Z","iopub.status.idle":"2023-10-25T10:21:16.084577Z","shell.execute_reply.started":"2023-10-25T10:21:16.084415Z","shell.execute_reply":"2023-10-25T10:21:16.084431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Create a DataFrame\ndf = pd.DataFrame({'Class': list(category_dict.keys()), 'Precision': scores_per_class})\n\n# Remove rows with NaN precision scores\ndf = df.dropna(subset=['Precision'])\n\n# Create a histogram\nplt.bar(df['Class'], df['Precision'])\nplt.xlabel('Class')\nplt.ylabel('Precision')\nplt.title('Precision per Class')\nplt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.085397Z","iopub.status.idle":"2023-10-25T10:21:16.085730Z","shell.execute_reply.started":"2023-10-25T10:21:16.085562Z","shell.execute_reply":"2023-10-25T10:21:16.085578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-10-25T10:21:16.087024Z","iopub.status.idle":"2023-10-25T10:21:16.087336Z","shell.execute_reply.started":"2023-10-25T10:21:16.087183Z","shell.execute_reply":"2023-10-25T10:21:16.087197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ram usage : 5-6 GB  \nGPU P100 usage : 6GB -> 85% usage  \ntraining time :  10 minutes et 23 secondes  \nprediction time : 0.1586 seconds, shape of 3116x3305 (9M de pixels)  \n                  0.2412 seconds, shape of 4088x5200 (21M de pixels)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}